{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import contextily as cx\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "import os\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import plotly.express as px\n",
    "\n",
    "import json\n",
    "import pyogrio\n",
    "\n",
    "from bokeh.io import output_notebook, show, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar, RadioButtonGroup,Slider,Widget\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "from bokeh.io.doc import curdoc\n",
    "from bokeh.layouts import row, column, gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside TimeUntil Arrival the region id is 4\n"
     ]
    }
   ],
   "source": [
    "regionIds = {\"ijs\": 4,\n",
    "             \"twente\": 5,\n",
    "             \"aa\": 13,\n",
    "             \"zhz\": 18,\n",
    "             \"bn\": 21,\n",
    "             \"bzo\": 22,\n",
    "             \"fgm\": 25}\n",
    "def adjust_time(timestr):\n",
    "    if isinstance(timestr, float):  # In case there's a float\n",
    "        return pd.NaT\n",
    "    dt = datetime.datetime.strptime(\"\".join(timestr[:10] + timestr[11:19]), '%Y-%m-%d%H:%M:%S')\n",
    "    # Check if the datetime is on or after March 31, 2024, 1:00 AM\n",
    "    if dt >= datetime.datetime(2024, 3, 31, 1, 0, 0):\n",
    "        return dt + datetime.timedelta(hours=2)  # Add 2 hours\n",
    "    else:\n",
    "        return dt + datetime.timedelta(hours=1)  # Add 1 hour\n",
    "\n",
    "connection_string_suffixs = {\"ijs\":\"aij_prd_V2\",\n",
    "                             \"twente\":\"aon_prd_V2\",\n",
    "                             \"aa\": \"ams_prd_V2\",\n",
    "                             \"zhz\":\"zhz_prd_V2\",\n",
    "                             \"bn\":\"bn_prd\",\n",
    "                             \"bzo\":\"bzo_prd\",\n",
    "                             \"fgm\":\"fgm_prd_V2\"}\n",
    "area = list(regionIds.keys())[0]\n",
    "start_date = datetime.datetime(2024, 3, 1,22,0,0)\n",
    "end_date = datetime.datetime(2024, 3, 10, 21, 59, 59) #since 2 hours are added after 31 SMarch, in order to get data until end of march, do until 22:00\n",
    "client = MongoClient(\"mongodb+srv://seconds:test%5EMe%5E%5E@cluster0.z9k9jkv.mongodb.net/\")\n",
    "dataset = client[connection_string_suffixs.get(area)]\n",
    "regionId = regionIds.get(area)\n",
    "\n",
    "\n",
    "Assigned_query = {\"$and\": \n",
    "                        [{\"requestUpdate.urgency\": {\"$in\": [\"A1\", \"A2\", \"A0\"]}},\n",
    "                        {\"timeWrittenByLogger\": {\"$gte\": start_date.isoformat() + 'Z',\"$lte\": end_date.isoformat() + 'Z'}},\n",
    "                        {\"requestUpdate.regionId\": regionId},\n",
    "                        {\"requestUpdate.isRelocation\":{\"$exists\":False}}\n",
    "                        ]}\n",
    "print(\"inside TimeUntil Arrival the region id is\", regionId)\n",
    "ups = dataset['updates']\n",
    "assignedCars012 = pd.DataFrame(list(ups.find(Assigned_query))) \n",
    "assignedCars012['timestamp'] = assignedCars012['time'].apply(adjust_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa 1 1 1 31\n",
      "not this month:1 for this area aa\n",
      "aa 2 1 2 29\n",
      "not this month:2 for this area aa\n",
      "aa 3 1 3 31\n",
      "not this month:3 for this area aa\n",
      "aa 4 1 4 30\n"
     ]
    }
   ],
   "source": [
    "from utilsMongoFuns import *\n",
    "lens = [31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "# area,startMonth,startDay,endMonth,endDay,boolean\n",
    "for area in [\"aa\",\"zhz\",\"bn\",\"bzo\",\"fgm\",\"ijs\"]:\n",
    "    for i in range(1,13):\n",
    "        try:\n",
    "            mongoDBimportTwente(area,i,1,i,lens[i-1]) #start and end date + boolean=False(1) as no saved tables yet\n",
    "        except:\n",
    "            print(f'not this month:{i} for this area {area}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDataTwente():\n",
    "    #twente_21=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/twente/Twente_ritten2021.xlsx')\n",
    "    twente_22=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/twente/Twente_ritten2022.xlsx')\n",
    "    #twente_21 = np.array(twente_21)\n",
    "    twente_22 = np.array(twente_22)\n",
    "\n",
    "    #twe_21=np.delete(twente_21,[0,3,4,5,6,7,8,9,10,11,12,13,14,17,18,19,20,21,22,23,24,25,26,27,28,-2,-1],axis=1)\n",
    "    twe_22=np.delete(twente_22,[0,3,4,5,6,7,8,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,-3,-2,-1],axis=1)\n",
    "    #twe_whole = np.vstack((np.array(twe_21),np.array(twe_22)))\n",
    "    twe_whole = twe_22\n",
    "    invalid_timestamps=[]\n",
    "    for i in tqdm(range(len(twe_whole))):\n",
    "        if (twe_whole[i,1]-twe_whole[i,0]).total_seconds()>3600: #time delta between call and ride assignment toolong 'f >1h\n",
    "            invalid_timestamps.append(i)\n",
    "    clean_set=np.delete(twe_whole,invalid_timestamps,axis=0) #only records correct calls regardeless of ridetype\n",
    "\n",
    "    clean_set=clean_set[[(type(clean_set[j,4])==str)&(type(clean_set[j,2])!=str) for j in range(len(clean_set))]]\n",
    "    df=pd.DataFrame({'CallTime':clean_set[:,0],'lat':clean_set[:,2].tolist(),'lon':clean_set[:,3].tolist(),'urgency':clean_set[:,4].tolist()})\n",
    "    gdf=gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "    gdf.crs='epsg:4326'\n",
    "\n",
    "    return gdf\n",
    "\n",
    "def extractDataFLGV():\n",
    "\n",
    "    # Read in data for GGD locally. Maybe implement it from link (sharepoint)\n",
    "    data_fld=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/fgm/FLD_08_21-09_22.xlsx')\n",
    "    #data_gvs=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/fgm/GVS_08_21-09_22.xlsx')\n",
    "    #flgv_post=np.vstack((np.array(data_fld)[:,2:],np.array(data_gvs)[:,2:]))\n",
    "    flgv_post=np.array(data_fld)[:,2:]\n",
    "    flgv_post=np.delete(flgv_post,[2,3,4,5,6,7,8,12,13,14,15,16,17,18,19,20,21,22],axis=1)\n",
    "\n",
    "    # Clean dataset from invalid runs\n",
    "    invalid_timestamps=[]\n",
    "    for i in tqdm(range(len(flgv_post))):\n",
    "        if (flgv_post[i,1]-flgv_post[i,0]).total_seconds()>3600: #time delta between call and ride assignment toolong 'f >1h\n",
    "            invalid_timestamps.append(i)\n",
    "    flgv_post = pd.DataFrame(np.delete(flgv_post,invalid_timestamps,axis=0)) #only records correct calls regardeless of ridetype\n",
    "    flgv_post.rename(columns={2:'Station',3:'xcoord',4:'ycoord',5:'urgency',0:'CallTime'},inplace=True)\n",
    "\n",
    "    # Select incidents that happened inside the region -- GFV here\n",
    "    gdf = gpd.GeoDataFrame(flgv_post, geometry=gpd.points_from_xy(flgv_post.xcoord, flgv_post.ycoord))\n",
    "    gdf.crs='epsg:28992'\n",
    "    gdf=gdf.to_crs(epsg=4326)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def make_hexagon_grids(code):\n",
    "\n",
    "    # Read in hexagon centres from local file -- maybe implement read directly from link/sharepoint.\n",
    "    hex_centres = [None]*4 # Initialize a list with 4 None elements\n",
    "    for i, region in enumerate(['Flevoland Gooi Vecht (FGM)','Zuid Holland Zuid (ZHZ)','Twente','IJsselland']):\n",
    "        hex_centres[i] = pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/geodata/Hex_coords_4regions.xlsx',region).drop('Unnamed: 0',axis=1).drop(0).reset_index().drop('index',axis=1)\n",
    "        hex_centres[i] = hex_centres[i].rename(columns={hex_centres[i].columns[1]: \"lon\", hex_centres[i].columns[0]: \"lat\"})\n",
    "        hex_centres[i] = hex_centres[i].reindex(columns=hex_centres[i].columns[::-1])\n",
    "        hex_centres[i].sort_values(by=['lon', 'lat']).reset_index().drop('index',axis=1)\n",
    "        hex_centres[i]['hexID'] = hex_centres[i].reset_index().index\n",
    "    \n",
    "    center_coords = hex_centres[code]\n",
    "    print('hex centres ready')\n",
    "    # Define the size of the hexagons    \n",
    "    avg_distance=np.mean([np.abs(center_coords.lon.loc[i+1]-center_coords.lon.loc[i]) for i in range(6)])\n",
    "    rad_km = avg_distance / np.sqrt(3) * 111.320 * np.cos(math.radians(center_coords.loc[5].lat))\n",
    "    hexagons = []\n",
    "    hex_vertices = []\n",
    "    for j in tqdm(range(len(center_coords))):\n",
    "        center_km = [center_coords.loc[j].lon * 111.320 * np.cos(math.radians(center_coords.loc[j].lat)) , center_coords.loc[j].lat * 110.574]\n",
    "        vertices = []  \n",
    "        for i in range(6):\n",
    "            angle = np.pi/6 + np.pi/3 * i\n",
    "            # find new vertices coords and immediately convert back to deg \n",
    "            ver_lon = (center_km[0] + rad_km * np.cos(angle)) / (111.320 * np.cos(math.radians(center_coords.loc[j].lat)))  \n",
    "            ver_lat = (center_km[1] + rad_km * np.sin(angle)) / 110.574\n",
    "            vertices.append((ver_lon,ver_lat))\n",
    "\n",
    "        hexagons.append(Polygon(vertices))\n",
    "        \n",
    "    # Create two empty grids (geo-dataframes) to fill with A1 and A2 data \n",
    "    hex_grid_A1=gpd.GeoDataFrame({'geometry': hexagons })\n",
    "    hex_grid_A1.crs='epsg:4326'\n",
    "    hex_grid_A2=gpd.GeoDataFrame({'geometry': hexagons })\n",
    "    hex_grid_A2.crs='epsg:4326'\n",
    "\n",
    "    hex_grids=[hex_grid_A1,hex_grid_A2]\n",
    "\n",
    "    return hex_grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeUntilArrival done\n",
      "Assigned Cars done\n",
      "dataframe obtained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [06:28<00:00, 55.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average (mean) number of advices per incident is 381 while the median number of advices is 148.\n",
      "The average (mean) number of unique advices per incident is 5.09 while the median number of unique advices is 5.\n",
      "Between 01/01/2024 and 01/29/2024, the number of unique dispatch advices for urgencies A0/A1/A2 is 18991. The total number of dispatch advices for A-incidents is 1442052.\n",
      "The average (mean) number of unique daily advices is 654.86.\n",
      "DispatchAdvices done\n",
      "<class 'str'> <class 'str'> <class 'str'> <class 'str'>\n",
      "DispatchStats done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "day is out of range for month",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# area,startMonth,startDay,endMonth,endDay,boolean\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m13\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     adviceRanks \u001b[38;5;241m=\u001b[39m \u001b[43mmongoDBimportTwente\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtwente\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#start and end date + boolean=False(1) as no saved tables yet\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MC\\OneDrive - Stokhos BV\\Stokhos\\developer\\demandMatrix\\utilsMongoFuns.py:360\u001b[0m, in \u001b[0;36mmongoDBimportTwente\u001b[1;34m(area, startMonth, startDay, endMonth, endDay, boolean)\u001b[0m\n\u001b[0;32m    358\u001b[0m start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2024\u001b[39m, startMonth, startDay, \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m#since 2 hours are added after 31 of March, in order to get data until end of march, do until 22:00\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendMonth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendDay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m TimeUntilArrival012_df, uniqueIDs                             \u001b[38;5;241m=\u001b[39m TimeUntilArrival012(dataset,start_date,end_date)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeUntilArrival done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: day is out of range for month"
     ]
    }
   ],
   "source": [
    "from utilsMongoFuns import *\n",
    "lens = [31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "# area,startMonth,startDay,endMonth,endDay,boolean\n",
    "for i in range(1,13):\n",
    "    adviceRanks = mongoDBimportTwente(\"twente\",i,1,i,lens[i],1) #start and end date + boolean=False(1) as no saved tables yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49372/49372 [00:00<00:00, 262092.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hex centres ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [00:01<00:00, 1158.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexagons ready for FLGV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355/355 [00:00<00:00, 70208.31it/s]\n",
      "Filling grid with incs: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]\n",
      "Filling grid with incs: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Import data on 1) gemeenten\n",
    "geemapNL=gpd.read_file(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/geodata/gadm41_NLD_2.json')\n",
    "geemapNLL=geemapNL.loc[geemapNL.ENGTYPE_2=='Municipality'] #excludes waterbodies\n",
    "\n",
    "# 2) GGd regions\n",
    "ggdmap=gpd.read_file(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/geodata/GGD_Regiogrenzen.json')\n",
    "\n",
    "# 3) stations     \n",
    "regionCode = int(input(\"Insert 1 for FLGV and 2 for Twente:_____\"))\n",
    "regios_dict = {1:\"FLGV\",2:\"Twente\"}\n",
    "# Give choice of num days and num months to make plot\n",
    "test_months= int(input(\"how many test months?\"))\n",
    "test_days  = int(input(\"how many test days?\"))\n",
    "\n",
    "if regionCode==1:\n",
    "    stationinfo=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/fgm/FLGVregio_info.xlsx','Station FLGV')\n",
    "    stationinfo.columns = stationinfo.iloc[0]\n",
    "    stationinfo=stationinfo.drop(stationinfo.columns[0],axis=1)\n",
    "    stationinfo=stationinfo.iloc[1:]\n",
    "    # municiplaities FLGV\n",
    "    fldgemten=[geemapNL['NAME_2'][i] for i in range(len(geemapNL)) if geemapNL['NAME_1'][i]=='Flevoland']\n",
    "    gvs_gemten=['Blaricum','GooiseMeren','Hilversum','Huizen','Laren','Weesp','Wijdemeren']\n",
    "    gementen=fldgemten+gvs_gemten \n",
    "    # retrieve datasets locally (FLGV)\n",
    "    incidents_gdf = extractDataFLGV()\n",
    "    hexgrids = make_hexagon_grids(0)\n",
    "elif regionCode==2:\n",
    "    stationinfo=pd.read_excel(r'C:/Users/MC/OneDrive - Stokhos BV/Stokhos/regiosdata/twente/Twente_stats.xlsx')\n",
    "    # Municipalities Twente\n",
    "    gementen=['Almelo','Borne','Dinkelland','Enschede','Haaksbergen','Hellendoorn','Hengelo','HofvanTwente','Losser','Oldenzaal','Rijssen','Tubbergen','Twenterand','Wierden']\n",
    "    # retrieve datasets locally (TWENTE)\n",
    "    incidents_gdf = extractDataTwente()\n",
    "    hexgrids = make_hexagon_grids(2)\n",
    "else:\n",
    "    print(\"must insert 1 or 2\")\n",
    "print(f'hexagons ready for {regios_dict[regionCode]}')\n",
    "\n",
    "# 4) stations GDF taking dataframe 'stationinfo' from 'if selected ggd regio'\n",
    "statgdf=gpd.GeoDataFrame(stationinfo, geometry=gpd.points_from_xy(stationinfo.lon, stationinfo.lat))\n",
    "statgdf.crs='epsg:4326'\n",
    "\n",
    "# 5) define GDF for munuicipalities in the selected ggd regio using list 'gementen'\n",
    "gee_gdf=geemapNL.loc[[geemapNL['NAME_2'][i] in gementen for i in tqdm(range(len(geemapNL)))]]\n",
    "gee_gdf.loc[:, 'geometry'] = gee_gdf.translate(xoff=-0.005)\n",
    "\n",
    "# Check that the correct region is being plotted by running\n",
    "# gee_gdf.plot()\n",
    "\n",
    "# 6) Only keep incidents that occured inside the region \n",
    "gdf_within = incidents_gdf.loc[incidents_gdf.within(gee_gdf.geometry.unary_union)].reset_index().drop('index',axis=1)\n",
    "gdf_within = gdf_within.assign(lon = gdf_within.geometry.x.to_list())\n",
    "gdf_within = gdf_within.assign(lat = gdf_within.geometry.y.to_list())\n",
    "\n",
    "# 7) Fill in hex_grids A1 and A2 with incidents fom the region per month/day\n",
    "for i,urg in enumerate(['A1','A2']):\n",
    "    hex_grid=hexgrids[i]\n",
    "    for month in tqdm(range(1,int(test_months)+1), desc=\"Filling grid with incs\"):\n",
    "        for weekday in range(test_days):\n",
    "            ridesMonthDay = gdf_within[(gdf_within.urgency==f'{urg}') & (gdf_within['CallTime'].dt.weekday==weekday)  & (gdf_within['CallTime'].dt.month==month)]\n",
    "            # normalisation is number of mondays,sundays ets in any given month.\n",
    "            normalisation = len(np.unique(gdf_within[(gdf_within['CallTime'].dt.weekday==weekday)  & (gdf_within['CallTime'].dt.month==month)].CallTime.dt.date))            \n",
    "            if normalisation==0: \n",
    "                normalisation=1\n",
    "            # in following line rides are assigned to hexagons\n",
    "            column_to_insert = [ridesMonthDay.within(hex_grid.loc[i].geometry).sum()/normalisation for i in range(len(hex_grid))]\n",
    "            hex_grid.insert(np.shape(hex_grid)[1],f\"month:{month}:-day:{weekday+1}\",column_to_insert)\n",
    "\n",
    "# 8) Define a sequential multi-hue color palette and reverse color order so that dark blue is highest obesity.\n",
    "Day_Labels = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "Month_Labels= [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "palette = brewer['Blues'][8]\n",
    "palette = palette[::-1]\n",
    "\n",
    "# 9) Function that returns json_data for the month+weekday+urgency selected \n",
    "def json_data(selectedMonth,selectedDay,selectedUrgency):\n",
    "    # convert from A 1/2 to 0/1 index\n",
    "    ur = selectedUrgency-1\n",
    "    # Select urgencyGrid \n",
    "    urg_gdf = hexgrids[int(ur)]\n",
    "    # Pull selected month+day from geodataframe into df\n",
    "    gdf_mn_day = urg_gdf.filter(like=f\"month:{selectedMonth}:-day:{selectedDay}\")\n",
    "    # Retrieve geofeatures (hexagons) from gdf\n",
    "    gdf = urg_gdf.iloc[:,0:1]\n",
    "    # Merge the hexagons (gdf) with the data (gdf_mn_day)\n",
    "    merged =  gpd.GeoDataFrame(pd.concat([gdf,gdf_mn_day],axis=1))\n",
    "    # Bokeh uses geojson formatting, representing geographical features, with json\n",
    "    mergedToLoad=merged.to_json()\n",
    "    # Convert to json\n",
    "    merged_json = json.loads(mergedToLoad)\n",
    "    # Convert to json preferred string-like object \n",
    "    json_data = json.dumps(merged_json)\n",
    "    return json_data\n",
    "# Input geojson source that contains features for starting plot when opening application\n",
    "geosource = GeoJSONDataSource(geojson = json_data(1,1,2))\n",
    "\n",
    "# 10) Define the callback function: update_plot which obv updates plots with values selcted on applet\n",
    "def update_plot(attr, old, new):\n",
    "\n",
    "    month = mon_slider.value\n",
    "    #day = day_slider.value\n",
    "    # Replace slider with RadGroup\n",
    "    day = rad_group.active + 1\n",
    "    urgency = urg_slider.value\n",
    "    new_data = json_data(month,day,urgency)        \n",
    "    # Update the plot based on the changed inputs\n",
    "    p = make_plot(month,day,urgency)\n",
    "    # Update the layout, clear the old document and display the new document\n",
    "    sliders = column(mon_slider,urg_slider,rad_group)\n",
    "    layout = column(p, sliders)\n",
    "    curdoc().clear()\n",
    "    curdoc().add_root(layout)\n",
    "    # Update the data\n",
    "    geosource.geojson = new_data\n",
    "\n",
    "# 11) Create a plotting function which defines what the plot looks like \n",
    "def make_plot(month,day,urgency):    \n",
    "  \n",
    "  date=f\"month:{month}:-day:{day}\"\n",
    "  urg = urgency - 1\n",
    "  urg_gdf = hexgrids[int(urg)]\n",
    "  # Set the format of the colorbar\n",
    "  min_range = np.array(urg_gdf.filter(like=f\"month:{month}:-day:{day}\").min())[0]\n",
    "  max_range = np.array(urg_gdf.filter(like=f\"month:{month}:-day:{day}\").max())[0]\n",
    "  # Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "  color_mapper = LinearColorMapper(palette = palette, low = min_range, high = max_range)\n",
    "  # Create color bar.\n",
    "  color_bar = ColorBar(color_mapper=color_mapper, label_standoff=18,border_line_color=None, location = (0, 0))\n",
    "\n",
    "  # Create figure object.\n",
    "  p = figure(title = f\"Average number of A{urgency} incidents on {Day_Labels[day-1]}\\'s of {Month_Labels[month]}\", \n",
    "            plot_height = 650, plot_width = 850,\n",
    "            toolbar_location = None)\n",
    "  p.xgrid.grid_line_color = None\n",
    "  p.ygrid.grid_line_color = None\n",
    "  p.axis.visible = False\n",
    "  # Add patch renderer to figure. \n",
    "  p.patches('xs','ys', source = geosource, fill_color = {'field' : date, 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)\n",
    "  # Specify color bar layout.\n",
    "  p.add_layout(color_bar, 'right')\n",
    "  return p\n",
    "\n",
    "# 12) Call the plotting function \n",
    "p = make_plot(1,1,2)\n",
    "\n",
    "# 13) Add checkbox group for weekdays(trial). \n",
    "rad_group = RadioButtonGroup(labels=Day_Labels[:test_days], active=0)\n",
    "rad_group.on_change('active', update_plot) # rad_group returns [i,j] if i,j clicked, otherwise [].\n",
    "\n",
    "# Make a MONTHS slider object \n",
    "mon_slider = Slider(title = 'Month',start = 1, end = test_months, step = 1, value = 1)\n",
    "mon_slider.on_change('value', update_plot)\n",
    "# Make a URGENCY slider object \n",
    "urg_slider = Slider(title = 'Urgency A',start = 1, end = 2, step = 1, value = 2)\n",
    "urg_slider.on_change('value', update_plot)\n",
    "# Make a column layout of widgetbox(slider) and plot, and add it to the current document\n",
    "# Display the current document\n",
    "sliders = column(mon_slider,urg_slider,rad_group)\n",
    "layout = column(p,sliders)\n",
    "#layout = column(p, widgetbox(mon_slider), widgetbox(day_slider), widgetbox(urg_slider))\n",
    "curdoc().add_root(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
